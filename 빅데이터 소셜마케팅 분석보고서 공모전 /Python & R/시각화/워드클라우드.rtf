{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fnil\fcharset129 AppleSDGothicNeo-Regular;\f1\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 Import as pandas as pd
\f1 \
\
coin_laundry_text = open("/Users/hankiho/Desktop/
\f0 \'b0\'f8\'b8\'f0\'c0\'fc
\f1  
\f0 \'c5\'a9\'b7\'d1\'b8\'b5
\f1  
\f0 \'c0\'da\'b7\'e1
\f1  
\f0 \'b9\'d7
\f1  
\f0 \'b5\'a5\'c0\'cc\'c5\'cd
\f1 /
\f0 \'c5\'a9\'b7\'d1\'b8\'b5
\f1  
\f0 \'b5\'a5\'c0\'cc\'c5\'cd
\f1 /
\f0 \'ba\'ed\'b7\'ce\'b1\'d7
\f1 /
\f0 \'b3\'bb\'bf\'eb
\f1 /
\f0 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad\'b0\'cb\'bb\'f6\'b0\'e1\'b0\'fa
\f1 .txt", 'r',encoding='utf-8').read()\
\
import nltk\
from konlpy.tag import Twitter; t = Twitter()\
\
df_coin_laundry_text = str(coin_laundry_text)\
\
#
\f0 \'c6\'af\'bc\'f6\'b9\'ae\'c0\'da\'bf\'cd
\f1  
\f0 \'bc\'fd\'c0\'da
\f1  
\f0 \'c1\'a6\'b0\'c5
\f1 \
import re\
\
def cleanText(readData):\
    text = re.sub('[-=+,#/\\?:^$.@*\\"\uc0\u8251 ~&%
\f0 \'a4\'fd
\f1 !
\f0 \'a1\'bb
\f1 \\\\\'91|\\(\\)\\[\\]\\<\\>`\\'\'85
\f0 \'a1\'b7
\f1 ]', '', readData)\
    return text\
\
tokens_ko = t.morphs(cleanText(df_coin_laundry_text))\
\
stop_words = ['
\f0 \'b0\'a1
\f1 ','
\f0 \'bf\'e4
\f1 ','
\f0 \'b4\'e4\'ba\'af
\f1 ','
\f0 \'c0\'bb
\f1 ','
\f0 \'bc\'f6
\f1 ','
\f0 \'bf\'a1
\f1 ','
\f0 \'c1\'fa\'b9\'ae
\f1 ','
\f0 \'c1\'a6
\f1 ','
\f0 \'b8\'a6
\f1 ','
\f0 \'c0\'cc
\f1 ','
\f0 \'b5\'b5
\f1 ','
\f0 \'b4\'d0\'b3\'d7\'c0\'d3
\f1 ','
\f0 \'c0\'d4\'b4\'cf\'b4\'d9
\f1 ','
\f0 \'b0\'cb\'bb\'f6
\f1 ','
\f0 \'b5\'c8
\f1 ','
\f0 \'b4\'f5
\f1 ',\
              '
\f0 \'c1\'c1
\f1 ','
\f0 \'b4\'c2
\f1 ','
\f0 \'b7\'ce
\f1 ','
\f0 \'c0\'b8\'b7\'ce
\f1 ','
\f0 \'b0\'cd
\f1 ','
\f0 \'c0\'ba
\f1 ','
\f0 \'b4\'d9
\f1 ','
\f0 \'b4\'cf\'b4\'d9
\f1 ','
\f0 \'b4\'eb
\f1 ','
\f0 \'b5\'e9
\f1 ','
\f0 \'be\'c8\'b3\'e7\'c7\'cf\'bc\'bc\'bf\'e4
\f1 ','
\f0 \'c0\'cc\'b6\'f3
\f1 ','
\f0 \'c7\'cf\'bc\'bc\'bf\'e4
\f1 ','
\f0 \'b3\'d7
\f1 ','1',\
              '
\f0 \'bf\'cd
\f1 ','
\f0 \'b5\'e5\'b7\'b9\'bc\'ad
\f1 ','
\f0 \'bf\'c0
\f1 ','
\f0 \'b6\'a7\'b9\'ae
\f1 ','
\f0 \'be\'ee
\f1 ','
\f0 \'b3\'aa
\f1 ','
\f0 \'c5\'db
\f1 ','
\f0 \'c0\'fb
\f1 ','
\f0 \'b5\'fc
\f1 ',\
              '
\f0 \'b5\'e9
\f1 ','
\f0 \'b5\'a5
\f1 ','
\f0 \'c0\'c7
\f1 ','
\f0 \'b6\'a7
\f1 ','
\f0 \'b0\'da
\f1 ','
\f0 \'b0\'ed
\f1 ','
\f0 \'b0\'d4
\f1 ','
\f0 \'b3\'d7\'bf\'e4
\f1 ','
\f0 \'c7\'d1
\f1 ','
\f0 \'c0\'cf
\f1 ','
\f0 \'c7\'d2
\f1 ','
\f0 \'bf\'ac\'b0\'fc\'b0\'cb\'bb\'f6\'be\'ee
\f1 ','
\f0 \'c1\'a4\'b5\'b5
\f1 ','
\f0 \'b1\'e2
\f1 ','
\f0 \'c8\'a4
\f1 ',\
              '
\f0 \'c7\'cf\'b4\'c2
\f1 ','
\f0 \'c1\'d6
\f1 ','
\f0 \'b7\'c1\'b0\'ed
\f1 ','
\f0 \'c0\'ce\'b5\'a5
\f1 ','
\f0 \'b0\'c5
\f1 ','
\f0 \'c1\'bb
\f1 ','
\f0 \'b4\'c2\'b5\'a5
\f1 ','
\f0 \'c0\'fc
\f1 ','
\f0 \'b8\'b9\'c0\'cc
\f1 ','
\f0 \'c0\'cc\'b6\'f3
\f1 ','
\f0 \'c1\'a4\'b5\'b5
\f1 ','
\f0 \'c7\'df
\f1 ','
\f0 \'c1\'d6\'b7\'c1
\f1 ','
\f0 \'b1\'ee\'c1\'f6
\f1 ','
\f0 \'bf\'a1\'be\'ee
\f1 '\
              '
\f0 \'c7\'cf\'b3\'aa
\f1 ','
\f0 \'c0\'cc\'bb\'f3
\f1 ','
\f0 \'b9\'b9
\f1 ','
\f0 \'b1\'ee
\f1 ','
\f0 \'c0\'d6\'b4\'c2
\f1 ','
\f0 \'c0\'df
\f1 ','
\f0 \'bd\'c0\'b4\'cf\'b4\'d9
\f1 ','
\f0 \'b4\'d9\'b8\'e9
\f1 ','
\f0 \'c7\'df
\f1 ','
\f0 \'c1\'d6\'b7\'c1
\f1 ','
\f0 \'b9\'ab\'c1\'f6
\f1 ','
\f0 \'c7\'d5\'b4\'cf\'b4\'d9
\f1 ','
\f0 \'a4\'d0\'a4\'d0
\f1 ','
\f0 \'bf\'a1\'bc\'ad
\f1 ',\
              '
\f0 \'c1\'f6
\f1 ','
\f0 \'c0\'d6
\f1 ','
\f0 \'b8\'f8
\f1 ','
\f0 \'c8\'c4
\f1 ','
\f0 \'c1\'df
\f1 ','
\f0 \'c1\'d9
\f1 ','
\f0 \'b0\'fa
\f1 ','
\f0 \'be\'ee\'b6\'b2
\f1 ','
\f0 \'b1\'e2\'ba\'bb
\f1 ','
\f0 \'bf\'a1\'bc\'ad
\f1 ','
\f0 \'c7\'d8
\f1 ','
\f0 \'b4\'dc\'be\'ee
\f1 ','
\f0 \'b6\'f3\'b0\'ed
\f1 ','
\f0 \'c7\'d5
\f1 ','
\f0 \'b0\'a1\'bf\'e4
\f1 ','
\f0 \'ba\'ce\'c5\'cd
\f1 '\
              '1','2','3','4','5','6','7','8','9','10','11','12','
\f0 \'c0\'af\'c4\'a1\'bf\'f8
\f1 ','
\f0 \'c1\'c1\'c0\'ba
\f1 ','
\f0 \'c0\'fa
\f1 ','
\f0 \'b4\'dc
\f1 ','
\f0 \'bb\'ef\'bc\'ba
\f1 ','
\f0 \'bf\'a1\'be\'ee
\f1 ']\
\
tokens_ko = [each_word for each_word in tokens_ko if each_word not in stop_words]\
\
ko = nltk.Text(tokens_ko, name='
\f0 \'c4\'da\'c0\'ce\'bc\'bc\'c5\'b9\'b9\'e6
\f1 ')\
ko.vocab().most_common(2) #
\f0 \'bf\'b7\'bf\'a1
\f1  
\f0 \'b0\'b9\'bc\'f6\'b4\'c2
\f1  
\f0 \'b8\'ee\'b0\'b3
\f1  
\f0 \'b3\'aa\'bf\'d4\'b4\'c2\'c1\'f6
\f1 \
\
from matplotlib import rc\
rc('font', family='AppleGothic')\
plt.rcParams['axes.unicode_minus'] = False\
\
plt.figure(figsize=(15,6))\
ko.plot(50) \
plt.show()\
\
from wordcloud import WordCloud, STOPWORDS\
from PIL import Image\
data = ko.vocab().most_common(50)\
clothes = np.array(Image.open('/Users/hankiho/Desktop/
\f0 \'be\'e7\'ba\'b9
\f1 .png'))\
\
plt.figure(figsize=(8,8))\
plt.imshow(clothes, cmap=plt.cm.gray, interpolation='bilinear')\
plt.axis('off')\
plt.show()\
\
wordcloud = WordCloud(font_path='/Users/hankiho/anaconda3/lib/python3.6/site-packages/pytagcloud/fonts/NanumBarunGothic.ttf',\
                      relative_scaling = 0.3,\
                      stopwords=STOPWORDS,\
                      background_color='white',\
                      mask=clothes\
                      ).generate_from_frequencies(dict(data))\
plt.figure(figsize=(16,8))\
plt.imshow(wordcloud)\
save_img = '
\f0 \'bf\'f6\'b5\'e5\'c5\'ac\'b6\'f3\'bf\'ec\'b5\'e5
\f1 .png'\
plt.savefig(save_img)\
plt.axis("off")\
plt.show()}