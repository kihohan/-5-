{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset129 AppleSDGothicNeo-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\qj\partightenfactor0

\f0\fs24 \cf0 import pandas as pd\
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0
\cf0 from selenium import webdriver\
from bs4 import BeautifulSoup as bs\
import time\
from selenium.webdriver.common.keys import Keys\
\
#keyword = str(input('
\f1 \'c5\'b0\'bf\'f6\'b5\'e5
\f0 : '))\
keyword = '
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 '\
\
chromedriver_dir = '/Users/hankiho/Downloads/chromedriver'\
driver = webdriver.Chrome(chromedriver_dir)\
driver.get("https://www.instagram.com/explore/tags/" + keyword + "/")\
\
#
\f1 \'c7\'d8\'bd\'ac\'c5\'c2\'b1\'d7
\f0  
\f1 \'b0\'d4\'bd\'c3\'b9\'b0
\f0  
\f1 \'b0\'b9\'bc\'f6
\f0 \
totalCount = driver.find_element_by_class_name('g47SY').text\
time.sleep(3)\
print("totalCount :", totalCount)\
\
content = []\
texts=''\
f=open('/Users/hankiho/Desktop/'+keyword+'
\f1 \'b0\'cb\'bb\'f6\'b0\'e1\'b0\'fa
\f0 .txt','w', encoding='utf-8')\
\
driver.find_element_by_class_name('_9AhH0').click() #
\f1 \'c3\'b9\'b9\'f8\'c2\'b0
\f0  
\f1 \'c6\'f7\'bd\'ba\'c6\'ae
\f0  
\f1 \'c5\'ac\'b8\'af
\f0 \
time.sleep(4)\
soup = bs(driver.page_source,'html.parser')\
obj = soup.find('div', class_='C4VMK')\
content = obj.find('span')\
hash_tag = content.find_all('a')\
\
for i in range(len(hash_tag)):\
    texts=texts+hash_tag[i].text\
    \
    \
texts=texts.replace('  ','')\
f.write(texts+'\\n\\n')\
#content.append(obj.find('span').text)\
print(texts)\
\
driver.find_element_by_xpath('/html/body/div[3]/div[1]/div/div/a').click() #
\f1 \'b5\'ce\'b9\'f8\'a4\'8a
\f0  
\f1 \'c6\'f7\'bd\'ba\'c5\'cd
\f0  
\f1 \'b3\'d1\'b1\'e2\'b1\'e2
\f0 \
time.sleep(1)\
soup = bs(driver.page_source,'html.parser')\
obj = soup.find('div', class_='C4VMK')\
content = obj.find('span')\
hash_tag = content.find_all('a')\
\
text = ''\
for i in range(len(hash_tag)):\
    texts=texts+hash_tag[i].text\
    \
    \
texts=texts.replace('  ','')\
f.write(texts+'\\n\\n')\
#content.append(obj.find('span').text)\
print(texts)\
\
i = 0\
while i < 40000:\
    try:\
        driver.find_element_by_xpath('/html/body/div[3]/div[1]/div/div/a[2]').click() #
\f1 \'b5\'ce\'b9\'f8\'a4\'8a
\f0  
\f1 \'c6\'f7\'bd\'ba\'c5\'cd
\f0  
\f1 \'b3\'d1\'b1\'e2\'b1\'e2
\f0 \
        time.sleep(5)\
        soup = bs(driver.page_source,'html.parser')\
        obj = soup.find('div', class_='C4VMK')\
        content = obj.find('span')\
        hash_tag = content.find_all('a')\
\
        texts = ''\
        for i in range(len(hash_tag)):\
            texts=texts+hash_tag[i].text\
\
        texts=texts.replace('  ','')\
        f.write(texts+'\\n\\n')\
        i = i+1\
    except:\
        time.sleep(10)\
        print ('
\f1 \'bf\'a1\'b7\'af
\f0 ')\
        pass}