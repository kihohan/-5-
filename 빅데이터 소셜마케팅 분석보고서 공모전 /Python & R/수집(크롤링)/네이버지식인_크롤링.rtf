{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset129 AppleSDGothicNeo-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 import time\
import pandas as pd\
import os\
from selenium import webdriver\
from bs4 import BeautifulSoup as bs\
\
driver = webdriver.Chrome('/Users/hankiho/Downloads/chromedriver')\
\
def link_sc():\
    link_list = driver.find_elements_by_css_selector('ul.basic1 > li > dl > dt > a ')\
    link_urls=[ k.get_attribute('href') for k in link_list ]\
    \
    for data in link_urls:\
        try:\
            driver.get(data)\
            soup = bs(driver.page_source, 'html.parser')\
\
            #
\f1 \'b0\'d4\'bd\'c3\'b1\'db\'bf\'a1\'bc\'ad
\f0  
\f1 \'c1\'a6\'b8\'f1
\f0  
\f1 \'c3\'df\'c3\'e2
\f0 \
            title = soup.select('div.title')[0].get_text()\
            print(title)\
            df_file.write(title + '\\n')\
        \
            #
\f1 \'b3\'bb\'bf\'eb
\f0  
\f1 \'b0\'a1\'c1\'ae\'bf\'c0\'b1\'e2
\f0 \
            answer1 = soup.find_all('div',\{'class':'c-heading__content'\})[0].get_text()\
            print(answer1)\
            df_file.write(answer1 + '\\n')\
\
            #
\f1 \'b4\'e4\'ba\'af
\f0  
\f1 \'b0\'a1\'c1\'ae\'bf\'c0\'b1\'e2
\f0 \
            answer2 = soup.select('p')\
            answer2 = ' '.join([ tags.get_text() for tags in answer2 ])\
            print(answer2)\
            df_file.write(answer2 + '\\n\\n')\
\
            #dict
\f1 \'c7\'fc\'c5\'c2\'b7\'ce
\f0  
\f1 \'b8\'b8\'b5\'e9\'be\'ee
\f0  
\f1 \'b0\'e1\'b0\'fa
\f0  list
\f1 \'bf\'a1
\f0  
\f1 \'c0\'fa\'c0\'e5
\f0 \
            ar_list.append(\{'title' : title, 'answer2' : answer1, 'answer2' : answer2\})\
            print(ar_list)\
\
        except :\
            pass\
\
keyword = input('
\f1 \'b0\'cb\'bb\'f6\'be\'ee\'b8\'a6
\f0  
\f1 \'c0\'d4\'b7\'c2\'c7\'cf\'bc\'bc\'bf\'e4
\f0 : ')\
ar_list = []\
df_file=open('/Users/hankiho/Desktop/
\f1 \'c1\'f6\'bd\'c4\'c0\'ce
\f0  
\f1 \'b0\'e1\'b0\'fa
\f0 .txt', 'w', encoding='utf-8')\
\
for i in range(1, 5):\
    #try:\
        url1 = "https://kin.naver.com/search/list.nhn?query="\
        url2="&page="\
        url=url1+keyword+url2+str(i)\
        print(url)\
        driver.get(url)\
        link_sc()\
    #except :\
    #    print('
\f1 \'bf\'a1\'b7\'af
\f0 ')\
    #    pass\
\
print(ar_list)\
df_file.close()}