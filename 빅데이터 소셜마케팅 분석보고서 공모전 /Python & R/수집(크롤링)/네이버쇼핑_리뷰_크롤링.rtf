{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 import pandas as pd\
from selenium import webdriver\
import bs4\
import time\
from selenium.webdriver.common.keys import Keys\
\
chromedriver_dir = '/Users/hankiho/Downloads/chromedriver'\
driver = webdriver.Chrome(chromedriver_dir)\
driver.get("https://search.shopping.naver.com/detail/detail.nhn?nv_mid=8733310247&cat_id=50007045&frm=NVSHATC&query=%EC%8A%A4%ED%83%80%EC%9D%BC%EB%9F%AC&NaPm=ct%3Djsbvzf9c%7Cci%3D88eefd09a71ff8b95c1891ba7da858009a69994f%7Ctr%3Dslsl%7Csn%3D95694%7Chk%3Dfcddee54e5ea365a5a4b4f33895b7daca5ca3e33"\
\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
li[0].find('div','atc').text\
\
review = []\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(2)").click()\
\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(3)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(4)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(5)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(6)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(7)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(8)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(9)").click()\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(10)").click()\
\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a.next").click()\
\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(12)").click()\
\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
driver.find_element_by_css_selector("#_review_paging > a:nth-child(13)").click()\
\
source = driver.page_source\
bs = bs4.BeautifulSoup(source,'html')\
review_obj = bs.find('ul',id = '_review_list')\
li = review_obj.find_all('li')\
\
for i in range(19):\
    review.append(li[3 * i].find('div','atc').text)\
    #print (li[3 * i].find('div','atc').text)\
\
df = pd.DataFrame(review)\
\
df.to_csv('/Users/hankiho/Desktop/df_result.csv', index=False, encoding="utf-8-sig") \
\
}