{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset129 AppleSDGothicNeo-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 keyword = str(input('
\f1 \'c5\'b0\'bf\'f6\'b5\'e5
\f0 : '))\
\
from bs4 import BeautifulSoup \
from urllib.request import urlopen\
import urllib\
from tqdm import tqdm_notebook\
import time\
import pandas as pd\
\
tmp1 = 'https://search.naver.com/search.naver?sm=tab_hty.top&where=article'\
html = tmp1 + '&sm=tab_jum&ie=utf8&query=\{key_word\}&start=\{num\}' \
\
title = []\
content = []\
for n in tqdm_notebook(range(1,1000,10)): # 1
\f1 \'c6\'e4\'c0\'cc\'c1\'f6\'bf\'a1
\f0  10
\f1 \'b0\'b3
\f0 \
    response = urlopen(html.format(num=n, key_word=urllib.parse.quote(keyword)))\
    naver_cafe_obj = BeautifulSoup(response, "html.parser")\
    naver_cafe_body = naver_cafe_obj.find_all('li','sh_cafe_top')\
    \
    for n in range(len(naver_cafe_body)):\
        title.append(naver_cafe_body[n].find('a','sh_cafe_title').text)\
        content.append(naver_cafe_body[n].find('dd','sh_cafe_passage').text)\
    time.sleep(0.5)\
\
df_title = pd.DataFrame(title,columns = ['
\f1 \'c1\'a6\'b8\'f1
\f0 '])\
df_content = pd.DataFrame(content,columns = ['
\f1 \'b3\'bb\'bf\'eb\'bf\'e4\'be\'e0
\f0 '])\
df_naver_cafe = pd.concat([df_title,df_content],axis = 1)\
#df_naver_cafe.to_csv(r'/Users/hankiho/Desktop/df_result.csv',encoding='cp949')\
\
df_naver_cafe.to_csv('/Users/hankiho/Desktop/df_result.csv', index=False, encoding="utf-8-sig") }