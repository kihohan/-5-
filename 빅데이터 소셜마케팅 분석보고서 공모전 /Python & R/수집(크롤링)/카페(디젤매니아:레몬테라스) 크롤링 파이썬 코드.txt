1. 네이버 카페 - 디젤매니아 크롤링 코드 - 에어드레서
from time import sleep
import pandas as pd
import os
from selenium import webdriver 
from bs4 import BeautifulSoup as bs
import time

driver = webdriver.Chrome('python_data/chromedriver')
keyword = '에어드레서'
base_url = "https://m.cafe.naver.com/ArticleSearchList.nhn?search.query=" + keyword +  \
"&search.searchBy=0&search.sortBy=date&search.clubid=11262350&search.option=0&search.defaultValue=1"
driver.get(base_url)

for page_num in range(1,3):
    driver.find_element_by_xpath('//*[@id="moreButton"]').click()
    time.sleep(1)

article_list = driver.find_elements_by_css_selector('div.search_list > div#articleList > ul.lst_section >li >a ')
article_urls = [ i.get_attribute('href') for i in article_list ]
article_urls

for article in article_urls:
    try:
        driver.get(article)
        soup = bs(driver.page_source, 'html.parser')
        
        title = soup.select('h2.tit')[0].get_text()
        print(title)
        
        date = soup.select("span.date.font_l")[0].get_text()
        print(date)
        
        content_tags = soup.select('#postContent')[0].select('p')
        content = ' '.join([ tags.get_text() for tags in content_tags ])
        print(content)
         
        content_tags1 = soup.select('div.section_comment')[0].select('p.txt')
        content1 = ' '.join([ tags1.get_text() for tags1 in content_tags1 ])
        
        
        ar_list.append({'title': title, 'date': date, 'content': content, 'content1': content1})
    except :
        print('에러')
        pass

    
print(ar_list)

cafe_df = pd.DataFrame(ar_list)

cafe_df.to_csv("python_data/디젤매니아(에어드레서).csv",index=False, encoding="utf-8-sig")

2.네이버 카페 - 디젤매니아 크롤링 코드 ? 스타일러
from time import sleep
import pandas as pd
import os
from selenium import webdriver 
from bs4 import BeautifulSoup as bs
import time

driver = webdriver.Chrome('python_data/chromedriver')
keyword = '스타일러'
base_url = "https://m.cafe.naver.com/ArticleSearchList.nhn?search.query=" + keyword +  \
"&search.searchBy=0&search.sortBy=date&search.clubid=11262350&search.option=0&search.defaultValue=1"
driver.get(base_url)

for page_num in range(1,3):
    driver.find_element_by_xpath('//*[@id="moreButton"]').click()
    time.sleep(1)

article_list = driver.find_elements_by_css_selector('div.search_list > div#articleList > ul.lst_section >li >a ')
article_urls = [ i.get_attribute('href') for i in article_list ]
article_urls

for article in article_urls:
    try:
        driver.get(article)
        soup = bs(driver.page_source, 'html.parser')
        
        title = soup.select('h2.tit')[0].get_text()
        print(title)
        
        date = soup.select("span.date.font_l")[0].get_text()
        print(date)
        
        content_tags = soup.select('#postContent')[0].select('p')
        content = ' '.join([ tags.get_text() for tags in content_tags ])
        print(content)
         
        content_tags1 = soup.select('div.section_comment')[0].select('p.txt')
        content1 = ' '.join([ tags1.get_text() for tags1 in content_tags1 ])
        
        
        ar_list.append({'title': title, 'date': date, 'content': content, 'content1': content1})
    except :
        print('에러')
        pass

    
print(ar_list)

cafe_df = pd.DataFrame(ar_list)

cafe_df.to_csv("python_data/디젤매니아(스타일러).csv",index=False, encoding="utf-8-sig")

3.네이버 카페 - 디젤매니아 크롤링 코드 ? 에어드레서
from time import sleep
import pandas as pd
import os
from selenium import webdriver 
from bs4 import BeautifulSoup as bs
import time

driver = webdriver.Chrome('python_data/chromedriver')
keyword = '에어드레서'
base_url = "https://m.cafe.naver.com/ArticleSearchList.nhn?search.query=" + keyword +  \
"&search.searchBy=0&search.sortBy=date&search.clubid=10298136&search.option=0&search.defaultValue=1"
driver.get(base_url)

for page_num in range(1,3):
    driver.find_element_by_xpath('//*[@id="moreButton"]').click()
    time.sleep(1)

article_list = driver.find_elements_by_css_selector('div.search_list > div#articleList > ul.lst_section >li >a ')
article_urls = [ i.get_attribute('href') for i in article_list ]
article_urls

for article in article_urls:
    try:
        driver.get(article)
        soup = bs(driver.page_source, 'html.parser')
        
        title = soup.select('h2.tit')[0].get_text()
        print(title)
        
        date = soup.select("span.date.font_l")[0].get_text()
        print(date)
        
        content_tags = soup.select('#postContent')[0].select('p')
        content = ' '.join([ tags.get_text() for tags in content_tags ])
        print(content)
         
        content_tags1 = soup.select('div.section_comment')[0].select('p.txt')
        content1 = ' '.join([ tags1.get_text() for tags1 in content_tags1 ])
        
        
        ar_list.append({'title': title, 'date': date, 'content': content, 'content1': content1})
    except :
        print('에러')
        pass

    
print(ar_list)

cafe_df = pd.DataFrame(ar_list)

cafe_df.to_csv("python_data/레몬테라스(에어드레서).csv",index=False, encoding="utf-8-sig")

4. 네이버 카페 - 디젤매니아 크롤링 코드 ? 스타일러

from time import sleep
import pandas as pd
import os
from selenium import webdriver 
from bs4 import BeautifulSoup as bs
import time

driver = webdriver.Chrome('python_data/chromedriver')
keyword = '스타일러'
base_url = "https://m.cafe.naver.com/ArticleSearchList.nhn?search.query=" + keyword +  \
"&search.searchBy=0&search.sortBy=date&search.clubid=10298136&search.option=0&search.defaultValue=1"
driver.get(base_url)

for page_num in range(1,3):
    driver.find_element_by_xpath('//*[@id="moreButton"]').click()
    time.sleep(1)

article_list = driver.find_elements_by_css_selector('div.search_list > div#articleList > ul.lst_section >li >a ')
article_urls = [ i.get_attribute('href') for i in article_list ]
article_urls

for article in article_urls:
    try:
        driver.get(article)
        soup = bs(driver.page_source, 'html.parser')
        
        title = soup.select('h2.tit')[0].get_text()
        print(title)
        
        date = soup.select("span.date.font_l")[0].get_text()
        print(date)
        
        content_tags = soup.select('#postContent')[0].select('p')
        content = ' '.join([ tags.get_text() for tags in content_tags ])
        print(content)
         
        content_tags1 = soup.select('div.section_comment')[0].select('p.txt')
        content1 = ' '.join([ tags1.get_text() for tags1 in content_tags1 ])
        
        
        ar_list.append({'title': title, 'date': date, 'content': content, 'content1': content1})
    except :
        print('에러')
        pass

    
print(ar_list)

cafe_df = pd.DataFrame(ar_list)

cafe_df.to_csv("python_data/레몬테라스(스타일러).csv",index=False, encoding="utf-8-sig")