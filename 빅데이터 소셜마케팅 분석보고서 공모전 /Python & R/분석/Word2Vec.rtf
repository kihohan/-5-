{\rtf1\ansi\ansicpg949\cocoartf1671\cocoasubrtf200
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset129 AppleSDGothicNeo-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 import pandas as pd\
from konlpy.tag import Twitter; t = Twitter()\
import gensim\
from gensim.models import word2vec\
import re\
\

\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 _
\f1 \'c3\'bc\'c7\'e8\'b4\'dc
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6
\f0 _
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  
\f1 \'c3\'bc\'c7\'e8\'b4\'dc
\f0 )
\f1 \'b0\'cb\'bb\'f6\'b0\'e1\'b0\'fa
\f0 .txt", 'r',encoding='utf-8').read()\
\

\f1 \'bb\'a1\'b7\'a1\'b9\'e6\'bf\'a1\'bc\'ad
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c4\'ab\'c6\'e4
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 ).csv')\
\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'bc\'ee\'c7\'ce\'b8\'ae\'ba\'e4
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'bc\'ee\'c7\'ce\'b8\'ae\'ba\'e4
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'bc\'ee\'c7\'ce\'b8\'ae\'ba\'e4
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 ).csv')\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'bc\'ee\'c7\'ce\'b8\'ae\'ba\'e4
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'bc\'ee\'c7\'ce\'b8\'ae\'ba\'e4
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'bc\'ee\'c7\'ce\'b8\'ae\'ba\'e4
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 ).csv')\
\

\f1 \'b5\'f0\'c1\'a9\'b8\'c5\'b4\'cf\'be\'c6
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b5\'f0\'c1\'a9\'b8\'c5\'b4\'cf\'be\'c6
\f0 /
\f1 \'b5\'f0\'c1\'a9\'b8\'c5\'b4\'cf\'be\'c6
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 ).csv')\

\f1 \'b5\'f0\'c1\'a9\'b8\'c5\'b4\'cf\'be\'c6
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b5\'f0\'c1\'a9\'b8\'c5\'b4\'cf\'be\'c6
\f0 /
\f1 \'b5\'f0\'c1\'a9\'b8\'c5\'b4\'cf\'be\'c6
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 ).csv')\
\

\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 2000).csv')\

\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 2000).txt", 'r',encoding='utf-8').read()\
\

\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 _
\f1 \'b4\'f1\'b1\'db
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0  
\f1 \'b4\'f1\'b1\'db
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 ).csv')\

\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 _
\f1 \'b4\'f1\'b1\'db
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0  
\f1 \'b4\'f1\'b1\'db
\f0 /
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 ).csv')\
\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 ).csv')\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 ).csv')\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 (
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0 ).csv')\
\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  =  open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 /
\f1 \'b3\'bb\'bf\'eb
\f0 /
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af\'b0\'cb\'bb\'f6\'b0\'e1\'b0\'fa
\f0 .txt", 'r',encoding='utf-8').read()\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 /
\f1 \'b3\'bb\'bf\'eb
\f0 /
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad\'b0\'cb\'bb\'f6\'b0\'e1\'b0\'fa
\f0 .txt", 'r',encoding='utf-8').read()\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'ba\'ed\'b7\'ce\'b1\'d7
\f0 /
\f1 \'b3\'bb\'bf\'eb
\f0 /
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2\'b0\'cb\'bb\'f6\'b0\'e1\'b0\'fa
\f0 .txt", 'r',encoding='utf-8').read()\
\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c1\'f6\'bd\'c4\'c0\'ce
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c1\'f6\'bd\'c4\'c0\'ce
\f0 /
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 .txt", 'r',encoding='utf-8').read()\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c1\'f6\'bd\'c4\'c0\'ce
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c1\'f6\'bd\'c4\'c0\'ce
\f0 /
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0 .txt", 'r',encoding='utf-8').read()\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c1\'f6\'bd\'c4\'c0\'ce
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = open("/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c1\'f6\'bd\'c4\'c0\'ce
\f0 /
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 .txt", 'r',encoding='utf-8').read()\
\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c4\'ab\'c6\'e4
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 (
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0 ).csv')\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c4\'ab\'c6\'e4
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 (
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 ).csv')\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0  = pd.read_csv('/Users/hankiho/Desktop/
\f1 \'b0\'f8\'b8\'f0\'c0\'fc
\f0  
\f1 \'c5\'a9\'b7\'d1\'b8\'b5
\f0  
\f1 \'c0\'da\'b7\'e1
\f0 /
\f1 \'c4\'ab\'c6\'e4
\f0 /
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 (
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0 ).csv')\
\
total = 
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0 _
\f1 \'c3\'bc\'c7\'e8\'b4\'dc
\f0  + 
\f1 \'b7\'b9\'b8\'f3\'c5\'d7\'b6\'f3\'bd\'ba
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  + 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  + 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0  + 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'ba\'ed\'b7\'ce\'b1\'d7
\f0 _
\f1 \'b3\'bb\'bf\'eb
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0  + 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c1\'f6\'bd\'c4\'c0\'ce
\f0 _
\f1 \'bd\'ba\'c5\'b8\'c0\'cf\'b7\'af
\f0  + 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c1\'f6\'bd\'c4\'c0\'ce
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0  + 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c1\'f6\'bd\'c4\'c0\'ce
\f0 _
\f1 \'bf\'a1\'be\'ee\'b5\'e5\'b7\'b9\'bc\'ad
\f0   \
\

\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0 .head(1)\
\
df_select = 
\f1 \'b3\'d7\'c0\'cc\'b9\'f6\'c4\'ab\'c6\'e4
\f0 _
\f1 \'c0\'c7\'b7\'f9\'b0\'fc\'b8\'ae\'b1\'e2
\f0 ['
\f1 \'b3\'bb\'bf\'eb\'bf\'e4\'be\'e0
\f0 ']\
df_select_list = df_select.tolist()\
\
twitter = Twitter()\
results = []\
lines = total\
\
for line in lines:\
    malist = twitter.pos(line, norm=True, stem=True)\
    r= []\
    \
    for word in malist:\
        if not word[1] in ["Josa", "Eomi", "Punctuation"]:\
            r.append(word[0])\
            \
    r1 = (" ".join(r)).strip()\
    results.append(r1)\
    #print(r1)\
\
data_file = 'df.data'\
with open(data_file, 'w', encoding='utf-8') as fp:\
    fp.write("\\n".join(results))\
\
data = word2vec.LineSentence(data_file)\
model = word2vec.Word2Vec(data, size=200, window=10, hs=1,min_count=2, sg=1)  #
\f1 \'b8\'f0\'b5\'a8\'c1\'b6\'b0\'c7
\f0 \
                                                                        \
model.save('df.model')\
\
model = word2vec.Word2Vec.load('df.model')\
\
model.most_similar(positive=['
\f1 \'bc\'ad\'b4\'d9
\f0 '], negative=['
\f1 \'b0\'a1\'b4\'d9
\f0 '], topn = 5) \
\
model.wv.similarity('
\f1 \'bc\'bc\'c5\'b9
\f0 ', '
\f1 \'bd\'ba\'c5\'b8
\f0 ') #
\f1 \'b4\'dc\'be\'ee
\f0  
\f1 \'b0\'a3
\f0  
\f1 \'c0\'af\'bb\'e7\'b5\'b5
\f0 \
\
model.wv.most_similar("
\f1 \'bc\'bc\'c5\'b9
\f0 ") #
\f1 \'b4\'dc\'be\'ee
\f0  
\f1 \'b0\'a3
\f0  
\f1 \'bf\'ac\'b1\'a4\'bc\'ba
\f0 \
\
# 
\f1 \'c6\'c4\'b6\'f3\'b8\'de\'c5\'cd\'b0\'aa
\f0  
\f1 \'c1\'f6\'c1\'a4
\f0 \
num_features = 1000 # 
\f1 \'b9\'ae\'c0\'da
\f0  
\f1 \'ba\'a4\'c5\'cd
\f0  
\f1 \'c2\'f7\'bf\'f8
\f0  
\f1 \'bc\'f6
\f0 \
min_word_count = 40 # 
\f1 \'c3\'d6\'bc\'d2
\f0  
\f1 \'b9\'ae\'c0\'da
\f0  
\f1 \'bc\'f6
\f0 \
num_workers = 4 # 
\f1 \'ba\'b4\'b7\'c4
\f0  
\f1 \'c3\'b3\'b8\'ae
\f0  
\f1 \'bd\'ba\'b7\'b9\'b5\'e5
\f0  
\f1 \'bc\'f6
\f0 \
context = 10 # 
\f1 \'b9\'ae\'c0\'da\'bf\'ad
\f0  
\f1 \'c3\'a2
\f0  
\f1 \'c5\'a9\'b1\'e2
\f0 \
downsampling = 1e-3 # 
\f1 \'b9\'ae\'c0\'da
\f0  
\f1 \'ba\'f3\'b5\'b5\'bc\'f6
\f0  Downsample\
\
# 
\f1 \'c3\'ca\'b1\'e2\'c8\'ad
\f0  
\f1 \'b9\'d7
\f0  
\f1 \'b8\'f0\'b5\'a8
\f0  
\f1 \'c7\'d0\'bd\'c0
\f0 \
from gensim.models import word2vec\
\
# 
\f1 \'b8\'f0\'b5\'a8
\f0  
\f1 \'c7\'d0\'bd\'c0
\f0 \
model = word2vec.Word2Vec(df_select_list, \
                          workers=num_workers, \
                          size=num_features, \
                          min_count=min_word_count,\
                          window=context,\
                          sample=downsampling)\
model\
\
# 
\f1 \'c7\'d0\'bd\'c0\'c0\'cc
\f0  
\f1 \'bf\'cf\'b7\'e1
\f0  
\f1 \'b5\'c7\'b8\'e9
\f0  
\f1 \'c7\'ca\'bf\'e4\'be\'f8\'b4\'c2
\f0  
\f1 \'b8\'de\'b8\'f0\'b8\'ae\'b8\'a6
\f0  unload 
\f1 \'bd\'c3\'c5\'b2\'b4\'d9
\f0 .\
model.init_sims(replace=True)\
\
model_name = '300features_40minwords_10text'\
# model_name = '300features_50minwords_20text'\
model.save(model_name)\
\
# 
\f1 \'c2\'fc\'b0\'ed
\f0  https://stackoverflow.com/questions/43776572/visualise-word2vec-generated-from-gensim\
from sklearn.manifold import TSNE\
import matplotlib as mpl\
import matplotlib.pyplot as plt\
import gensim \
import gensim.models as g\
\
model_name = '300features_40minwords_10text'\
model = g.Doc2Vec.load(model_name)\
vocab = list(model.wv.vocab)\
X = model[vocab]\
\
print(len(X))\
print(X[0][:10])\
tsne = TSNE(n_components=2)\
\
X_tsne = tsne.fit_transform(X[:30,:])\
df = pd.DataFrame(X_tsne, index=vocab[:30], columns=['x', 'y'])\
df.shape\
\
from matplotlib import rc\
rc('font', family='AppleGothic')\
plt.rcParams['axes.unicode_minus'] = False\
\
fig = plt.figure()\
fig.set_size_inches(40, 20)\
ax = fig.add_subplot(1, 1, 1)\
\
ax.scatter(df['x'], df['y'])\
\
for word, pos in df.iterrows():\
    ax.annotate(word, pos, fontsize=30)\
plt.show()}